{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Movie Recommendation.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "maNKFfr-BXco",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LNzbNI4SDXCm",
        "colab_type": "text"
      },
      "source": [
        "## **EXTRACTING ZIP FILE**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "se9HWgUqCl1U",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from zipfile import ZipFile\n",
        "\n",
        "# Create a ZipFile Object and load sample.zip in it\n",
        "with ZipFile('/content/drive/My Drive/movie_recommender.zip', 'r') as zipObj:\n",
        "   # Extract all the contents of zip file in current directory\n",
        "   zipObj.extractall()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ADvy3yazGMps",
        "colab_type": "text"
      },
      "source": [
        "## **BASIC INTRO**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4D4k-HoMCl4B",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        },
        "outputId": "a02ff193-e728-47a6-c760-d8ec7ed29111"
      },
      "source": [
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "\n",
        "text = [\"London Paris London\", \"Paris Paris London\"]\n",
        "\n",
        "# counts the no of words in sentences.\n",
        "cv = CountVectorizer()\n",
        "\n",
        "count_matrix = cv.fit_transform(text)\n",
        "print(count_matrix.toarray())\n",
        "# output : 1st array shows 2 same words i.e. London and 1 word Paris in sentence 1. \n",
        "# In 2nd array London frequency is just 1 and Paris frequncy is 2 so [1  2]\n",
        "\n",
        "# Now computing cosine similairty between 2 vectors or 2 arrays (2 arrays mean 2 sentences).\n",
        "similarity_scores = cosine_similarity(count_matrix)\n",
        "print(\"\\n Similarity score blw 2 sentences: \")\n",
        "print(similarity_scores)\n",
        "\n",
        "#output : 1st array [1.0, 0.8] means 1st sentence or array is compared with itself so it similarity score is 1. secondly 1st sentence or array is compared\n",
        "# with second sentence so similarity score is 0.8. same procedure goes with array 2. "
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[2 1]\n",
            " [1 2]]\n",
            "\n",
            " Similarity score blw 2 sentences: \n",
            "[[1.  0.8]\n",
            " [0.8 1. ]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_gYrgsbmGS0b",
        "colab_type": "text"
      },
      "source": [
        "# **WORKING ON REAL DATASET**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TNNTAE86Cl6R",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.metrics.pairwise import cosine_similarity"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xhPRAa7UCl9U",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "##Step 1: Read CSV File\n",
        "df = pd.read_csv('/content/movie_dataset.csv')\n",
        "\n",
        "##Step 2: Select key Features\n",
        "\n",
        "print(df.columns)\n",
        "features = ['keywords', 'cast', 'genres', 'director']\n",
        "\n",
        "##Step 3: Create a column in DF which combines all selected features as a single string. \n",
        "def combine_features(row):\n",
        "  return row[\"keywords\"] + \" \" + row[\"cast\"] + \" \" + row[\"genres\"] + \" \"+ row[\"director\"]\n",
        "  \n",
        "# Apply this function/transform to all the rows of the dataframe.\n",
        "df[\"combined_features\"] = df.apply(combine_features, axis = 1) # axis 1 mean row wise. pass 1 row at a time. \n",
        "print(df[\"combined_features\"].head())\n",
        "# you will get an error due to nan values in the dataset but in order to troubleshoot u use try and catch block to see which row in the dataframe is making trouble\n",
        "# without stoping the execution loop.\n"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eWBt4_DqCmD2",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        },
        "outputId": "e9f0a97a-81ec-40f4-9c8f-733d34788905"
      },
      "source": [
        "###### helper functions. Use them when needed #######\n",
        "def get_title_from_index(index):\n",
        "\treturn df[df.index == index][\"title\"].values[0]\n",
        "\n",
        "def get_index_from_title(title):\n",
        "\treturn df[df.title == title][\"index\"].values[0]\n",
        "\n",
        "##################################################\n",
        "\n",
        "##Step 1: Read CSV File\n",
        "df = pd.read_csv('/content/movie_dataset.csv')\n",
        "\n",
        "##Step 2: Select key Features\n",
        "\n",
        "print(df.columns)\n",
        "features = ['keywords', 'cast', 'genres', 'director']\n",
        "\n",
        "##Step 3: Create a column in DF which combines all selected features as a single string. \n",
        "def combine_features(row):\n",
        "  try:\n",
        "    return row[\"keywords\"] + \" \" + row[\"cast\"] + \" \" + row[\"genres\"] + \" \"+ row[\"director\"]\n",
        "  except:\n",
        "    print(\"Error: \", row)\n",
        "\n",
        "# so you see the error is occuring due to nan values.\n",
        "# so lets replace nan values in your selected columns\n",
        "\n",
        "for feature in features:\n",
        "  df[feature] = df[feature].fillna('') # filling nan in each column rows with empty string. \n",
        "\n",
        "# Apply this function/transform to all the rows of the dataframe.\n",
        "df[\"combined_features\"] = df.apply(combine_features, axis = 1) # axis 1 mean row wise. pass 1 row at a time. \n",
        "print(df[\"combined_features\"].head())\n",
        "# Now it will work perfectly blc we have replaced nan values in our selective columns with empty strings. \n"
      ],
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Index(['index', 'budget', 'genres', 'homepage', 'id', 'keywords',\n",
            "       'original_language', 'original_title', 'overview', 'popularity',\n",
            "       'production_companies', 'production_countries', 'release_date',\n",
            "       'revenue', 'runtime', 'spoken_languages', 'status', 'tagline', 'title',\n",
            "       'vote_average', 'vote_count', 'cast', 'crew', 'director'],\n",
            "      dtype='object')\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_za4e1A8CmIg",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 884
        },
        "outputId": "0a9858e8-0223-4924-da8a-21935b59e6b2"
      },
      "source": [
        "##Step 4: Create count matrix from this new combined column\n",
        "cv = CountVectorizer()\n",
        "count_matrix = cv.fit_transform(df[\"combined_features\"])\n",
        "\n",
        "##Step 5: Compute the Cosine Similarity based on the count_matrix\n",
        "cosine_sim = cosine_similarity(count_matrix)\n",
        "\n",
        "# Now doing prediction, a movie name is given, get the similar movies to this name.\n",
        "movie_user_likes = \"Avatar\"\n",
        "\n",
        "## Step 6: Get index of this movie from its title\n",
        "movie_index = get_index_from_title(movie_user_likes)\n",
        "print(\"Movie Index: \", movie_index)\n",
        "\n",
        "# so when u get movie index u need to go into cosine_sim array, go at the movie index.\n",
        "similar_mov_array = cosine_sim[movie_index]\n",
        "similar_mov_array = [round(i, 2) for i in similar_mov_array]\n",
        "print(similar_mov_array)\n",
        "\n",
        "# convert the array into a list of sorted numbers like. [(0, 1.0), (1, 0.3), (2, 0.5)...]\n",
        "similar_movies = list(enumerate(similar_mov_array))\n",
        "print(similar_movies)\n",
        "\n",
        "## Step 7: Get a list of similar movies in descending order of similarity score\n",
        "sorted_similar_movies = sorted(similar_movies, key = lambda x: x[1], reverse=True)\n",
        "print(sorted_similar_movies)\n",
        "\n",
        "## Step 8: Print titles of first 50 movies\n",
        "i = 0\n",
        "for movie in sorted_similar_movies:\n",
        "  print(get_title_from_index(movie[0]))\n",
        "  i += 1\n",
        "  if i > 50:\n",
        "    break\n"
      ],
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Avatar\n",
            "Guardians of the Galaxy\n",
            "Aliens\n",
            "Star Wars: Clone Wars: Volume 1\n",
            "Star Trek Into Darkness\n",
            "Star Trek Beyond\n",
            "Alien\n",
            "Lockout\n",
            "Jason X\n",
            "Moonraker\n",
            "The Helix... Loaded\n",
            "Gravity\n",
            "Planet of the Apes\n",
            "Galaxy Quest\n",
            "Jupiter Ascending\n",
            "The Wolverine\n",
            "Alien³\n",
            "Silent Running\n",
            "Zathura: A Space Adventure\n",
            "Cargo\n",
            "Trekkies\n",
            "Star Trek\n",
            "Lost in Space\n",
            "Babylon A.D.\n",
            "Wing Commander\n",
            "Oblivion\n",
            "The Fifth Element\n",
            "Titan A.E.\n",
            "AVP: Alien vs. Predator\n",
            "Dragonball Evolution\n",
            "The Empire Strikes Back\n",
            "John Carter\n",
            "Superman Returns\n",
            "Starship Troopers\n",
            "Divergent\n",
            "Soldier\n",
            "The Abyss\n",
            "Memoirs of an Invisible Man\n",
            "The Astronaut's Wife\n",
            "The Black Hole\n",
            "Machete Kills\n",
            "Damnation Alley\n",
            "The Ice Pirates\n",
            "Captain America: Civil War\n",
            "Oz: The Great and Powerful\n",
            "Men in Black\n",
            "The Time Machine\n",
            "Star Trek: Insurrection\n",
            "Space Cowboys\n",
            "The One\n",
            "Sheena\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DHl-oN7rCmKx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eo3brICrCmPE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zAMg_aDuCmWF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uc6B8kiTCmYT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "znENSIfcCmT8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DlB23aYHCmRe",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vB8j2PtbCmNN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qcWnOcquCmHH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S1rDhOgeCmCI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eTvpSSN8CmAp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}